{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/01/30 22:23:12 WARN Utils: Your hostname, raja-Latitude-3410 resolves to a loopback address: 127.0.1.1; using 192.168.1.33 instead (on interface wlp0s20f3)\n",
      "25/01/30 22:23:12 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/01/30 22:23:13 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark=pyspark.sql.SparkSession.builder.appName(\"myapp\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-----------+-----------------+-----------------+-------+-----+-----+-------+----------------------+-----------------+--------------+------------------+-------------------+-----------------+----------+-----------+-----------+\n",
      "|Station Liscense No|stationName|         latitude|        longitude|zipCode| city|state|country|isLoadBalancingEnabled|stationInputPower|ChargePoint Id| chargePointVendor|   chargePointModel|meterSerialNumber|socketType|connectorId|unitCostAmt|\n",
      "+-------------------+-----------+-----------------+-----------------+-------+-----+-----+-------+----------------------+-----------------+--------------+------------------+-------------------+-----------------+----------+-----------+-----------+\n",
      "|             TN0123|        SIV|9.449637291523294|77.78316020965576| 682020|Test1|   TN|  India|                 FALSE|                0|      KL0123_1|VENTEST98420212512|MYTEST1984202123512|MYSER984202123512|   CHAdeMO|          3|         20|\n",
      "+-------------------+-----------+-----------------+-----------------+-------+-----+-----+-------+----------------------+-----------------+--------------+------------------+-------------------+-----------------+----------+-----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.read.option(\"header\",\"true\").csv(\"data.csv\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spark=spark.read.option(\"header\",\"true\").csv(\"data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Station Liscense No: string (nullable = true)\n",
      " |-- stationName: string (nullable = true)\n",
      " |-- latitude: string (nullable = true)\n",
      " |-- longitude: string (nullable = true)\n",
      " |-- zipCode: string (nullable = true)\n",
      " |-- city: string (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      " |-- country: string (nullable = true)\n",
      " |-- isLoadBalancingEnabled: string (nullable = true)\n",
      " |-- stationInputPower: string (nullable = true)\n",
      " |-- ChargePoint Id: string (nullable = true)\n",
      " |-- chargePointVendor: string (nullable = true)\n",
      " |-- chargePointModel: string (nullable = true)\n",
      " |-- meterSerialNumber: string (nullable = true)\n",
      " |-- socketType: string (nullable = true)\n",
      " |-- connectorId: string (nullable = true)\n",
      " |-- unitCostAmt: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_spark.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spark_infer=spark.read.option(\"header\",\"true\").csv(\"data.csv\",inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Station Liscense No: string (nullable = true)\n",
      " |-- stationName: string (nullable = true)\n",
      " |-- latitude: double (nullable = true)\n",
      " |-- longitude: double (nullable = true)\n",
      " |-- zipCode: integer (nullable = true)\n",
      " |-- city: string (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      " |-- country: string (nullable = true)\n",
      " |-- isLoadBalancingEnabled: boolean (nullable = true)\n",
      " |-- stationInputPower: integer (nullable = true)\n",
      " |-- ChargePoint Id: string (nullable = true)\n",
      " |-- chargePointVendor: string (nullable = true)\n",
      " |-- chargePointModel: string (nullable = true)\n",
      " |-- meterSerialNumber: string (nullable = true)\n",
      " |-- socketType: string (nullable = true)\n",
      " |-- connectorId: integer (nullable = true)\n",
      " |-- unitCostAmt: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_spark_infer.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spark=spark.read.csv(\"data.csv\",header=True,inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-----------+-----------------+-----------------+-------+-----+-----+-------+----------------------+-----------------+--------------+------------------+-------------------+-----------------+----------+-----------+-----------+\n",
      "|Station Liscense No|stationName|         latitude|        longitude|zipCode| city|state|country|isLoadBalancingEnabled|stationInputPower|ChargePoint Id| chargePointVendor|   chargePointModel|meterSerialNumber|socketType|connectorId|unitCostAmt|\n",
      "+-------------------+-----------+-----------------+-----------------+-------+-----+-----+-------+----------------------+-----------------+--------------+------------------+-------------------+-----------------+----------+-----------+-----------+\n",
      "|             TN0123|        SIV|9.449637291523294|77.78316020965576| 682020|Test1|   TN|  India|                 false|                0|      KL0123_1|VENTEST98420212512|MYTEST1984202123512|MYSER984202123512|   CHAdeMO|          3|         20|\n",
      "+-------------------+-----------+-----------------+-----------------+-------+-----+-----+-------+----------------------+-----------------+--------------+------------------+-------------------+-----------------+----------+-----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_spark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Station Liscense No',\n",
       " 'stationName',\n",
       " 'latitude',\n",
       " 'longitude',\n",
       " 'zipCode',\n",
       " 'city',\n",
       " 'state',\n",
       " 'country',\n",
       " 'isLoadBalancingEnabled',\n",
       " 'stationInputPower',\n",
       " 'ChargePoint Id',\n",
       " 'chargePointVendor',\n",
       " 'chargePointModel',\n",
       " 'meterSerialNumber',\n",
       " 'socketType',\n",
       " 'connectorId',\n",
       " 'unitCostAmt']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_spark.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Station Liscense No='TN0123', stationName='SIV', latitude=9.449637291523294, longitude=77.78316020965576, zipCode=682020, city='Test1', state='TN', country='India', isLoadBalancingEnabled=False, stationInputPower=0, ChargePoint Id='KL0123_1', chargePointVendor='VENTEST98420212512', chargePointModel='MYTEST1984202123512', meterSerialNumber='MYSER984202123512', socketType='CHAdeMO', connectorId=3, unitCostAmt=20)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_spark.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|stationName|\n",
      "+-----------+\n",
      "|        SIV|\n",
      "+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_spark.select(\"stationName\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df_spark.select(\"stationName\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------------+\n",
      "|stationName|         latitude|\n",
      "+-----------+-----------------+\n",
      "|        SIV|9.449637291523294|\n",
      "+-----------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_spark.select([\"stationName\",\"latitude\"]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Station Liscense No', 'string'),\n",
       " ('stationName', 'string'),\n",
       " ('latitude', 'double'),\n",
       " ('longitude', 'double'),\n",
       " ('zipCode', 'int'),\n",
       " ('city', 'string'),\n",
       " ('state', 'string'),\n",
       " ('country', 'string'),\n",
       " ('isLoadBalancingEnabled', 'boolean'),\n",
       " ('stationInputPower', 'int'),\n",
       " ('ChargePoint Id', 'string'),\n",
       " ('chargePointVendor', 'string'),\n",
       " ('chargePointModel', 'string'),\n",
       " ('meterSerialNumber', 'string'),\n",
       " ('socketType', 'string'),\n",
       " ('connectorId', 'int'),\n",
       " ('unitCostAmt', 'int')]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_spark.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/01/30 22:34:45 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "[Stage 23:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------------+-----------+-----------------+-----------------+--------+-----+-----+-------+-----------------+--------------+------------------+-------------------+-----------------+----------+-----------+-----------+\n",
      "|summary|Station Liscense No|stationName|         latitude|        longitude| zipCode| city|state|country|stationInputPower|ChargePoint Id| chargePointVendor|   chargePointModel|meterSerialNumber|socketType|connectorId|unitCostAmt|\n",
      "+-------+-------------------+-----------+-----------------+-----------------+--------+-----+-----+-------+-----------------+--------------+------------------+-------------------+-----------------+----------+-----------+-----------+\n",
      "|  count|                  1|          1|                1|                1|       1|    1|    1|      1|                1|             1|                 1|                  1|                1|         1|          1|          1|\n",
      "|   mean|               NULL|       NULL|9.449637291523294|77.78316020965576|682020.0| NULL| NULL|   NULL|              0.0|          NULL|              NULL|               NULL|             NULL|      NULL|        3.0|       20.0|\n",
      "| stddev|               NULL|       NULL|             NULL|             NULL|    NULL| NULL| NULL|   NULL|             NULL|          NULL|              NULL|               NULL|             NULL|      NULL|       NULL|       NULL|\n",
      "|    min|             TN0123|        SIV|9.449637291523294|77.78316020965576|  682020|Test1|   TN|  India|                0|      KL0123_1|VENTEST98420212512|MYTEST1984202123512|MYSER984202123512|   CHAdeMO|          3|         20|\n",
      "|    max|             TN0123|        SIV|9.449637291523294|77.78316020965576|  682020|Test1|   TN|  India|                0|      KL0123_1|VENTEST98420212512|MYTEST1984202123512|MYSER984202123512|   CHAdeMO|          3|         20|\n",
      "+-------+-------------------+-----------+-----------------+-----------------+--------+-----+-----+-------+-----------------+--------------+------------------+-------------------+-----------------+----------+-----------+-----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_spark.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-----------+-----------------+-----------------+-------+-----+-----+-------+----------------------+-----------------+--------------+------------------+-------------------+-----------------+----------+-----------+-----------+------------------+\n",
      "|Station Liscense No|stationName|         latitude|        longitude|zipCode| city|state|country|isLoadBalancingEnabled|stationInputPower|ChargePoint Id| chargePointVendor|   chargePointModel|meterSerialNumber|socketType|connectorId|unitCostAmt|         newColumn|\n",
      "+-------------------+-----------+-----------------+-----------------+-------+-----+-----+-------+----------------------+-----------------+--------------+------------------+-------------------+-----------------+----------+-----------+-----------+------------------+\n",
      "|             TN0123|        SIV|9.449637291523294|77.78316020965576| 682020|Test1|   TN|  India|                 false|                0|      KL0123_1|VENTEST98420212512|MYTEST1984202123512|MYSER984202123512|   CHAdeMO|          3|         20|18.899274583046587|\n",
      "+-------------------+-----------+-----------------+-----------------+-------+-----+-----+-------+----------------------+-----------------+--------------+------------------+-------------------+-----------------+----------+-----------+-----------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_spark.withColumn(\"newColumn\",df_spark[\"latitude\"]*2).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-----------+-----------------+-----------------+-------+-----+-----+-------+----------------------+-----------------+--------------+------------------+-------------------+-----------------+----------+-----------+-----------+\n",
      "|Station Liscense No|stationName|         latitude|        longitude|zipCode| city|state|country|isLoadBalancingEnabled|stationInputPower|ChargePoint Id| chargePointVendor|   chargePointModel|meterSerialNumber|socketType|connectorId|unitCostAmt|\n",
      "+-------------------+-----------+-----------------+-----------------+-------+-----+-----+-------+----------------------+-----------------+--------------+------------------+-------------------+-----------------+----------+-----------+-----------+\n",
      "|             TN0123|        SIV|9.449637291523294|77.78316020965576| 682020|Test1|   TN|  India|                 false|                0|      KL0123_1|VENTEST98420212512|MYTEST1984202123512|MYSER984202123512|   CHAdeMO|          3|         20|\n",
      "+-------------------+-----------+-----------------+-----------------+-------+-----+-----+-------+----------------------+-----------------+--------------+------------------+-------------------+-----------------+----------+-----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_spark.drop(\"newColumn\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-----------+-----------------+-----------------+-------+-----+-----+-------+----------------------+-----------------+--------------+------------------+-------------------+-----------------+----------+-----------+-----------+\n",
      "|Station Liscense No|stationname|         latitude|        longitude|zipCode| city|state|country|isLoadBalancingEnabled|stationInputPower|ChargePoint Id| chargePointVendor|   chargePointModel|meterSerialNumber|socketType|connectorId|unitCostAmt|\n",
      "+-------------------+-----------+-----------------+-----------------+-------+-----+-----+-------+----------------------+-----------------+--------------+------------------+-------------------+-----------------+----------+-----------+-----------+\n",
      "|             TN0123|        SIV|9.449637291523294|77.78316020965576| 682020|Test1|   TN|  India|                 false|                0|      KL0123_1|VENTEST98420212512|MYTEST1984202123512|MYSER984202123512|   CHAdeMO|          3|         20|\n",
      "+-------------------+-----------+-----------------+-----------------+-------+-----+-----+-------+----------------------+-----------------+--------------+------------------+-------------------+-----------------+----------+-----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_spark.withColumnRenamed(\"stationName\",\"stationname\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark=SparkSession.builder.appName(\"myapp\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=spark.read.csv(\"data.csv\",header=True,inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------+------+----+\n",
      "|         Name|Experience|Salary| Age|\n",
      "+-------------+----------+------+----+\n",
      "|     John Doe|         5| 75000|  28|\n",
      "|   Jane Smith|      NULL| 92000|NULL|\n",
      "|   Ravi Kumar|        10|105000|  36|\n",
      "|  Maria Lopez|         3|  NULL|  25|\n",
      "|   Anil Singh|         7| 89000|  31|\n",
      "|         NULL|         4| 72000|NULL|\n",
      "|Carlos Garcia|      NULL|115000|  40|\n",
      "|    Wei Zhang|         6| 81000|  30|\n",
      "|   Nina Patel|         9|  NULL|  34|\n",
      "| Arjun Sharma|         2| 60000|  24|\n",
      "+-------------+----------+------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Experience: integer (nullable = true)\n",
      " |-- Salary: integer (nullable = true)\n",
      " |-- Age: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "cln_data=data.drop(\"Name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+----+\n",
      "|Experience|Salary| Age|\n",
      "+----------+------+----+\n",
      "|         5| 75000|  28|\n",
      "|      NULL| 92000|NULL|\n",
      "|        10|105000|  36|\n",
      "|         3|  NULL|  25|\n",
      "|         7| 89000|  31|\n",
      "|         4| 72000|NULL|\n",
      "|      NULL|115000|  40|\n",
      "|         6| 81000|  30|\n",
      "|         9|  NULL|  34|\n",
      "|         2| 60000|  24|\n",
      "+----------+------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cln_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+---+\n",
      "|Experience|Salary|Age|\n",
      "+----------+------+---+\n",
      "|         5| 75000| 28|\n",
      "|        10|105000| 36|\n",
      "|         7| 89000| 31|\n",
      "|         6| 81000| 30|\n",
      "|         2| 60000| 24|\n",
      "+----------+------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cln_data.dropna().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+---+\n",
      "|Experience|Salary|Age|\n",
      "+----------+------+---+\n",
      "|         5| 75000| 28|\n",
      "|        10|105000| 36|\n",
      "|         7| 89000| 31|\n",
      "|         6| 81000| 30|\n",
      "|         2| 60000| 24|\n",
      "+----------+------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cln_data.na.drop().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+---+\n",
      "|Experience|Salary|Age|\n",
      "+----------+------+---+\n",
      "|         5| 75000| 28|\n",
      "|        10|105000| 36|\n",
      "|         7| 89000| 31|\n",
      "|         6| 81000| 30|\n",
      "|         2| 60000| 24|\n",
      "+----------+------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### threshold\n",
    "cln_data.na.drop(thresh=3).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+---+\n",
      "|Experience|Salary|Age|\n",
      "+----------+------+---+\n",
      "|         5| 75000| 28|\n",
      "|        10|105000| 36|\n",
      "|         3|  NULL| 25|\n",
      "|         7| 89000| 31|\n",
      "|      NULL|115000| 40|\n",
      "|         6| 81000| 30|\n",
      "|         9|  NULL| 34|\n",
      "|         2| 60000| 24|\n",
      "+----------+------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### SUBSET\n",
    "cln_data.na.drop(subset=[\"Age\"]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "mis_data=data.na.fill(\"missing value\",\"Age\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------+------+----+\n",
      "|         Name|Experience|Salary| Age|\n",
      "+-------------+----------+------+----+\n",
      "|     John Doe|         5| 75000|  28|\n",
      "|   Jane Smith|      NULL| 92000|NULL|\n",
      "|   Ravi Kumar|        10|105000|  36|\n",
      "|  Maria Lopez|         3|  NULL|  25|\n",
      "|   Anil Singh|         7| 89000|  31|\n",
      "|         NULL|         4| 72000|NULL|\n",
      "|Carlos Garcia|      NULL|115000|  40|\n",
      "|    Wei Zhang|         6| 81000|  30|\n",
      "|   Nina Patel|         9|  NULL|  34|\n",
      "| Arjun Sharma|         2| 60000|  24|\n",
      "+-------------+----------+------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mis_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Imputer\n",
    "\n",
    "imputer=Imputer(inputCols=[\"Age\",\"Salary\",\"Experience\"],\n",
    "                outputCols=[c+\"_Imputed\" for c in [\"Age\",\"Salary\",\"Experience\"]],\n",
    "                strategy=\"mean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------+------+----+-----------+--------------+------------------+\n",
      "|         Name|Experience|Salary| Age|Age_Imputed|Salary_Imputed|Experience_Imputed|\n",
      "+-------------+----------+------+----+-----------+--------------+------------------+\n",
      "|     John Doe|         5| 75000|  28|         28|         75000|                 5|\n",
      "|   Jane Smith|      NULL| 92000|NULL|         31|         92000|                 5|\n",
      "|   Ravi Kumar|        10|105000|  36|         36|        105000|                10|\n",
      "|  Maria Lopez|         3|  NULL|  25|         25|         86125|                 3|\n",
      "|   Anil Singh|         7| 89000|  31|         31|         89000|                 7|\n",
      "|         NULL|         4| 72000|NULL|         31|         72000|                 4|\n",
      "|Carlos Garcia|      NULL|115000|  40|         40|        115000|                 5|\n",
      "|    Wei Zhang|         6| 81000|  30|         30|         81000|                 6|\n",
      "|   Nina Patel|         9|  NULL|  34|         34|         86125|                 9|\n",
      "| Arjun Sharma|         2| 60000|  24|         24|         60000|                 2|\n",
      "+-------------+----------+------+----+-----------+--------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "imputer.fit(data).transform(data).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PySpark Dataframes\n",
    "\n",
    "&,|,==\n",
    "~\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/01/31 21:02:29 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    }
   ],
   "source": [
    "### Filter operation\n",
    "from pyspark.sql import SparkSession\n",
    "filter_spark=SparkSession.builder.appName(\"filter\").getOrCreate()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "fil_data=filter_spark.read.csv(\"data.csv\",header=True,inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------+------+----+\n",
      "|         Name|Experience|Salary| Age|\n",
      "+-------------+----------+------+----+\n",
      "|     John Doe|         5| 75000|  28|\n",
      "|   Jane Smith|      NULL| 92000|NULL|\n",
      "|   Ravi Kumar|        10|105000|  36|\n",
      "|  Maria Lopez|         3|  NULL|  25|\n",
      "|   Anil Singh|         7| 89000|  31|\n",
      "|         NULL|         4| 72000|NULL|\n",
      "|Carlos Garcia|      NULL|115000|  40|\n",
      "|    Wei Zhang|         6| 81000|  30|\n",
      "|   Nina Patel|         9|  NULL|  34|\n",
      "| Arjun Sharma|         2| 60000|  24|\n",
      "+-------------+----------+------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fil_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "cln_fil_data=fil_data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----------+------+---+\n",
      "|        Name|Experience|Salary|Age|\n",
      "+------------+----------+------+---+\n",
      "|    John Doe|         5| 75000| 28|\n",
      "|  Ravi Kumar|        10|105000| 36|\n",
      "|  Anil Singh|         7| 89000| 31|\n",
      "|   Wei Zhang|         6| 81000| 30|\n",
      "|Arjun Sharma|         2| 60000| 24|\n",
      "+------------+----------+------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cln_fil_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+------+---+\n",
      "|      Name|Experience|Salary|Age|\n",
      "+----------+----------+------+---+\n",
      "|Ravi Kumar|        10|105000| 36|\n",
      "|Anil Singh|         7| 89000| 31|\n",
      "| Wei Zhang|         6| 81000| 30|\n",
      "+----------+----------+------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cln_fil_data.filter(\"Salary>80000\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+------+---+\n",
      "|      Name|Experience|Salary|Age|\n",
      "+----------+----------+------+---+\n",
      "|Ravi Kumar|        10|105000| 36|\n",
      "|Anil Singh|         7| 89000| 31|\n",
      "| Wei Zhang|         6| 81000| 30|\n",
      "+----------+----------+------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cln_fil_data.filter(cln_fil_data[\"Salary\"]>80000).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "|Salary|\n",
      "+------+\n",
      "| 75000|\n",
      "|105000|\n",
      "| 89000|\n",
      "| 81000|\n",
      "| 60000|\n",
      "+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cln_fil_data.select(\"Salary\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+\n",
      "|      Name|Salary|\n",
      "+----------+------+\n",
      "|Ravi Kumar|105000|\n",
      "|Anil Singh| 89000|\n",
      "+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cln_fil_data.filter((cln_fil_data[\"Salary\"]>80000) &\n",
    "                    (cln_fil_data[\"Experience\"]>=7)).select(\n",
    "                        [\"Name\",\"Salary\"]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------+\n",
      "|        Name|Salary|\n",
      "+------------+------+\n",
      "|    John Doe| 75000|\n",
      "|Arjun Sharma| 60000|\n",
      "+------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cln_fil_data.filter(~(cln_fil_data[\"Salary\"]>80000) &\n",
    "                    ~(cln_fil_data[\"Experience\"]>=7)).select(\n",
    "                        [\"Name\",\"Salary\"]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Group by and Aggregate function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "grp_spark=SparkSession.builder.appName(\"groupby\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "grp_data=grp_spark.read.csv(\"data_test.csv\",header=True,inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----------+------+----------+\n",
      "|         Name| Department|Salary|Experience|\n",
      "+-------------+-----------+------+----------+\n",
      "|     John Doe|    Finance| 75000|         5|\n",
      "|   Jane Smith|         HR| 92000|         8|\n",
      "|   Ravi Kumar|Engineering|105000|        10|\n",
      "|  Maria Lopez|  Marketing| 65000|         3|\n",
      "|   Anil Singh|      Sales| 89000|         7|\n",
      "|  Emily Davis|    Finance| 72000|         4|\n",
      "|Carlos Garcia|Engineering|115000|        12|\n",
      "|    Wei Zhang|         HR| 81000|         6|\n",
      "|   Nina Patel|  Marketing| 97000|         9|\n",
      "| Arjun Sharma|      Sales| 60000|         2|\n",
      "+-------------+-----------+------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "grp_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------+---------------+\n",
      "| Department|max(Salary)|max(Experience)|\n",
      "+-----------+-----------+---------------+\n",
      "|      Sales|      89000|              7|\n",
      "|Engineering|     115000|             12|\n",
      "|         HR|      92000|              8|\n",
      "|    Finance|      75000|              5|\n",
      "|  Marketing|      97000|              9|\n",
      "+-----------+-----------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "grp_data.groupBy(\"Department\").max().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------+---------------+\n",
      "| Department|avg(Salary)|avg(Experience)|\n",
      "+-----------+-----------+---------------+\n",
      "|      Sales|    74500.0|            4.5|\n",
      "|Engineering|   110000.0|           11.0|\n",
      "|         HR|    86500.0|            7.0|\n",
      "|    Finance|    73500.0|            4.5|\n",
      "|  Marketing|    81000.0|            6.0|\n",
      "+-----------+-----------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "grp_data.groupBy(\"Department\").mean().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----+\n",
      "| Department|count|\n",
      "+-----------+-----+\n",
      "|      Sales|    2|\n",
      "|Engineering|    2|\n",
      "|         HR|    2|\n",
      "|    Finance|    2|\n",
      "|  Marketing|    2|\n",
      "+-----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "grp_data.groupBy(\"Department\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|sum(Salary)|\n",
      "+-----------+\n",
      "|     851000|\n",
      "+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "grp_data.agg({\"Salary\":\"sum\"}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------------+\n",
      "|max(Salary)|max(Experience)|\n",
      "+-----------+---------------+\n",
      "|     115000|             12|\n",
      "+-----------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "grp_data.agg({\"Salary\":\"Max\",\"Experience\":\"Max\"}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
